{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 이론 - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이진 로지스틱 회귀 시그모이드 사용 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합격을 1, 불합격을 0이라고 하였을 때 그래프를 그려보면 아래와 같습니다.\n",
    "\n",
    "![](images/로지스틱.png)\n",
    "\n",
    "\n",
    "이러한 점들을 표현하는 그래프는 알파벳의 S자 형태로 표현됩니다. \n",
    "이러한  x와 y의 관계를 표현하기 위해서는 직선을 표현하는 함수가 아니라 S자 형태로 표현할 수 있는 함수가 필요합니다. 직선을 사용할 경우 보통 분류 작업이 제대로 동작하지 않습니다.  \n",
    "\n",
    "이번 예제의 경우 실제값. 즉, 레이블에 해당하는 **y가 0 또는 1**이라는 두 가지 값만을 가지므로, 이 문제를 풀기 위해서 **예측값은 0과 1사이의 값**을 가지도록 합니다. 0과 1사이의 값을 확률로 해석하면 문제를 풀기가 훨씬 용이해집니다.  \n",
    "**최종 예측값이 0.5보다 작으면 0으로 예측했다고 판단하고, 0.5보다 크면 1로 예측**했다고 판단합니다. \n",
    "만약 y=wx+b의 직선을 사용할 경우, y값이 음의 무한대부터 양의 무한대와 같은 큰 수들도 가질 수 있는데 이는 직선이 분류 문제에 적합하지 않은 두번째 이유입니다.\n",
    "\n",
    "출력이 0과 1사이의 값을 가지면서 S자 형태로 그려지는 함수로 시그모이드 함수(Sigmoid function)가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이진 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 로지스틱 회귀 (for 2개의 클래스 분류 문제)\n",
    "    - 목적변수가 A라면 1, B라면 0으로 고려\n",
    "    - 주어진 피처 x에 대해서, A가 될 확률을 p라고 하면 B가 될 확률은 1-p \n",
    "    - 임의의 x에 대해서 p가 0.5보다 크면 A로 분류, 작으면 B로 분류\n",
    "    \n",
    "- 이진 로지스틱 회귀에서 주어진 피처 x에 대해서 p를 얻어내기 위해서 y를 어떻게 고려해야 할까?  \n",
    "![](images/로시.png)\n",
    "    - **가설함수는 선형함수를 통해서 로짓 (logit)을 얻고, 시그모이드 (sigmoid)함수를 적용** \n",
    "        - (로짓을 통해 –무한대~+무한대 범위 -> 시그모이드 적용하여 0~1 범위로)\n",
    "        - 가설함수 = p (p: 1로 분류될 확률, 1-p: 0으로 분류될 확률)\n",
    "        - 로짓함수, 시그모이드함수\n",
    "            ![](images/로짓.png)![](images/시그.png)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 비용함수 - 교차 엔트로피\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- h: y가 1로 분류될 확률로 0~1 사이의 값을 가짐 (릿지+시그모이드)\n",
    "- y: 0 또는 1의 값\n",
    "- 좋은 가설함수 h란 h와 y가 비슷한 값을 가지는 것!!! -> 교차 엔트로피 사용\n",
    "\n",
    "![](images/코스트.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/이진비용.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/이진경사.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 시그모이드, 가설, 비용, 경사하강법 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 함수 (릿지+시그모이드)\n",
    "def hypothesis_function(x,theta):\n",
    "    z = np.dot(-x,theta)    # 릿지 ((381*4)*(4*1)=(381*1))\n",
    "    return sigmoid(z)       # 릿지 + 시그모이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수\n",
    "def compute_cost(x,y,theta):\n",
    "    m = y.shape[0]  # 데이터 수\n",
    "    J = (-1/m)*y.T.dot(np.log(hypothesis_function(x,theta)))+(1-y).T.dot(np.log(1-hypothesis_function(x,theta)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gradient(x,y,theta,iterations=10000,alpha=0.01):\n",
    "    m     = y.size\n",
    "    Cost  = []  # 100번 업데이트마다 비용\n",
    "    Theta = []  # 하이퍼 파라미터\n",
    "    \n",
    "    for I in range(iterations):\n",
    "        original_theta = theta\n",
    "        for i in range(theta.size): # 4번 반복\n",
    "            partial_marginal = x[:,i].reshape(-1,1)# x중 한 피처 -> 하나의 열벡터로!(381*1)\n",
    "            delta            = hypothesis_function(x,original_theta) - y # (381*1)\n",
    "            # 그래디언트 정의 (걍 받아들이기)\n",
    "            grad_i           = delta.T.dot(partial_marginal) # ((1*381)*(381*1)=1*1)\n",
    "            # 경사하강법으로 theta 업데이트\n",
    "            theta[i]         = theta[i] - alpha*grad_i\n",
    "        if I%100 ==0:\n",
    "            Theta.append(theta)\n",
    "            Cost.append(compute_cost(x,y,theta))\n",
    "    return theta,np.array(Cost),np.array(Theta)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Breast Cancer 데이터에 logistic 회귀 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame = False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=1234)\n",
    "X_train, X_test = X_train[:, :3], X_test[:, :3]\n",
    "# reshape 필수\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 1. 전처리 - 표준 스케일링\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "######## 1. 전처리 - train, test 데이터에 절편추가\n",
    "n, n_test = X_train.shape[0], X_test.shape[0]\n",
    "X_train, X_test = np.append(np.ones((n, 1)), X_train,axis=1), np.append(np.ones((n_test, 1)),X_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## 1. 전처리 - 하이퍼 파라미터(w) 초기화\n",
    "theta = np.ones((X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 2. 경사하강법으로 theta 업데이트\n",
    "theta, Cost, Theta = minimize_gradient(X_train,y_train,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 정확도: 93.18%\n",
      "테스트 데이터셋 정확도: 87.23%\n"
     ]
    }
   ],
   "source": [
    "######## 3. 정확도 측정\n",
    "y_train_pred = np.where(hypothesis_function(X_train,theta)>0.5,1,0)\n",
    "y_test_pred  = np.where(hypothesis_function(X_test,theta)>0.5,1,0)\n",
    "print(f'학습 데이터셋 정확도:{(y_train == y_train_pred).sum() / len(y_train) * 100: .2f}%')\n",
    "print(f'테스트 데이터셋 정확도:{(y_test == y_test_pred).sum() / len(y_test) * 100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LogisticRegression 클래스 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번과 달리 간단하게 로지스틱 회귀로 예측할 수 있음! (동일한 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33,random_state=1234)\n",
    "\n",
    "# 절편추가 불필요\n",
    "X_train = X_train.iloc[:, :3]\n",
    "X_test  = X_test.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 정확도: 93.18%\n",
      "테스트 데이터셋 정확도: 87.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=1234, max_iter=1000, C=100)    \n",
    "# C : 정규화 강도의 역수. 높은 값일수록 정규화가 덜 됨\n",
    "# solver 옵션(알고리즘)에 따라 다양한 방법으로 진행할 수 있음  \n",
    "\n",
    "clf          = clf.fit(X_train, y_train)    # 학습\n",
    "y_train_pred = clf.predict(X_train)         # 훈련 데이터 예측\n",
    "y_pred       = clf.predict(X_test)          # 테스트 데이터 예측\n",
    "\n",
    "print(f'학습 데이터셋 정확도:{(y_train == y_train_pred).sum() / len(y_train) * 100: .2f}%')\n",
    "print(f'테스트 데이터셋 정확도:{(y_test == y_pred).sum() / len(y_test) * 100: .2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
